---
title: "Forecast daily bike rental demand using time series models"
date: "`r Sys.Date()`"
output: html_document
author: "Daniel Wilkinson"
---

# About Data Analysis Report

This RMarkdown file contains the report of the data analysis done for the project on forecasting daily bike rental demand using time series models in R. It contains analysis such as data exploration, summary statistics and building the time series models. The final report was completed on `r date()`. 

**Data Description:**

This dataset contains the daily count of rental bike transactions between years 2011 and 2012 in Capital bikeshare system with the corresponding weather and seasonal information.

**Data Source:** https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset

**Relevant Paper:** 

Fanaee-T, Hadi, and Gama, Joao, 'Event labeling combining ensemble detectors and background knowledge', Progress in Artificial Intelligence (2013): pp. 1-15, Springer Berlin Heidelberg


**Objectives**

The objective is to build a short-term forecasting model for daily rentals using an ARIMA model. Before ARIMA is implemented, the data is evaluated for stationarity -  a pre-requisite for using ARIMA - and seasonal patterns.


# Task One: Load and explore the data

## Load data and install packages

```{r echo=FALSE}
## Import required packages
#install.packages("pacman")
library("pacman")
p_load("tidyverse","ggpubr","timetk","psych","skimr","DataExplorer",
       "tseries","modeltime","parsnip","rsample","lubridate")

```


## Describe and explore the data

**Step 1 - Import and clean the data**

```{r}
# Import the data
data <- read.csv("day.csv") # data is a data frame
# check structure of dataframe
str(data) # 731 rows and 16 variables
# convert dteday from character to date format
data$dteday <- as.Date(data$dteday) 

# Replace numeric weekdays with labeled factor
data <- data %>%
  mutate(weekday = factor(weekday,
                          levels = 0:6,
                          labels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")))




```

**Step 2 - Explore the data**

```{r}

glimpse(data)
# summary of the data to check for any weird values
summary(data)
## We can see that RH ranges from 0%. This is a physical impossibility on Earth and not conceivable in the humid subtropical climate of DC. It may be an artefact.
## All variables are treated as continuous variables in summary(), resulting in binary entries - either 0 or 1 - like workingday, having median values between 0 and 1, but that has no meaning.


# generate deeper EDA report
DataExplorer::create_report(data)
# shows no missing values
# month, season, weathersit and weekday are discrete variables - shown in univeriate distribution
## qq plot shows how normally the data is distributed. It is intended for continuous variables - discrete or categorical variables such as weekday or season - are not appropriate for such a plot type.

# What effect does temperature have on the average number of bikes being hired?
data %>%
  select(dteday, season, temp, weekday, cnt) %>%
  group_by(season, weekday) %>%
  summarise(avg_cnt = mean(cnt), mean_t_c = mean(temp * 41)) # adjusting the mean temperature to °C
# --> The hotter the temperature, the more bikes are being rented out

ggplot(data, aes(x = dteday, y = temp)) + geom_point() + labs(x = "Date", y="Temperature (°C)")
# the temperature fluctuates from approximately 6°C to 33°C over 2011. The lowest temperature seems larger at the end of than 2011 but no significance test has been run on it.

temp_adjusted = data$temp * 41

boxplot_temp_by_year <- data %>%
  mutate(
    temp_c = temp * 41
  ) %>%
  ggplot(aes(x = factor(yr), y = temp_c)) +
  geom_boxplot() +
  scale_x_discrete(labels = c("0" = "2011", "1" = "2012")) +
  labs(
    x = "Year",
    y = "Temperature (°C)"
  ) + theme_pubr()

boxplot_temp_by_year
# which peaks are offpeak, onpeak?

seasonal_peaks <- data %>%
  group_by(season) %>%
  summarise(total_rentals = sum(cnt), .groups = "drop") %>%
  arrange(desc(total_rentals))
seasonal_peaks

monthly_peaks <- data %>%
  group_by(mnth) %>%
  summarise(total_rentals = sum(cnt), .groups = "drop") %>%
  arrange(desc(total_rentals))
monthly_peaks


```

## Temperature range
In 2011, the temperature ranges from `r round(min(temp_adjusted),1)`°C to `r round(max(temp_adjusted),1)`°C with a median of `r round(median(temp_adjusted),1)`°C. The temperatures are not significantly different in 2012 but appear to be slightly higher, especially when comparing the medians. The range of values in 2012 is also narrower.

## Peak season
The month-based peak season is in August, June and September. There is a clear drop in bike rentals in April, November, March and December. In terms of yearly seasons, Fall is the peak season, followed by Summer, Winter and then Spring.



# Task Two: Create interactive time series plots

In this task, three time series are plotted:

1. the number of bikes rented over time
2. the number of casual bike renters over time
3. the number of casual bike renters by week day. 

```{r}
## Read about the timetk package
# ?timetk

# how many bikes are rented over time
riders_ts <- data %>%
  plot_time_series(data$dteday, cnt, .y_lab = "Number of Bikes")
riders_ts

# how many casual riders are there over time
casual_rider_ts <- data %>%
  plot_time_series(data$dteday, casual, .y_lab = "Number of Casual Riders")
casual_rider_ts


# how many casual riders are there over time by day of the week
casual_riders_by_weekday <- data %>%
  group_by(weekday) %>%
  plot_time_series(dteday, casual, .facet_ncol=2, .y_lab = "Number of Casual Riders", .title = "Number of Casual Riders vs Time by Week Day")
casual_riders_by_weekday

registered_riders_by_weekday <- data %>%
  group_by(weekday) %>%
  plot_time_series(dteday, registered, .facet_ncol=2, .y_lab = "Number of Registered Riders", .title = "Number of Registered Riders vs Time by Week Day")
registered_riders_by_weekday

```
*Interpretation*

There are consistently fewer casual riders taking trips on work days than on Saturdays and Sundays, suggesting casual users ride for leisure rather than commuting. There is a mid-year peak and at drop at the end of the year, consistent with seasonal leisure behaviour.

There are consistently more registered riders than casual riders. There is less fluctuation in the smoothed trend line across week days than the casual riders, especially Monday to Friday. This indicates that registered users are primarily commuters with regular weekday usage and reduced weekend activity. 
# Task Three: Smooth time series data

```{r}

plot_time_series(
  .data       = data,
  .date_var   = dteday,
  .value      = cnt,
  .smooth     = TRUE,        # enables smoothing
  .interactive = FALSE,      # set TRUE for plotly
  .title      = "Smoothed Daily Bike Rentals Over Time",
  .y_lab      = "Number of Riders",
  .x_lab      = "Date"
)


```
*Interpretation*

The black line is for actual daily rental counts and it is spiky due to the daily variability. The blue, smoothed Loess line shows the underlying long-term trend. There is rising adoption in Jan-June 2011 which may reflect a recent launch of the bike hire system or be due to weather changes. There is a plateau between July 2011 and December 2011 where growth stabilises. The market may be saturated by early adopters, or the uptake is affected by the end of summer or other external influences like limits to infrastructure. There is another growth phase between Jan and Sept 2012 which may be due to increased membership, more bike infrastructure e.g. stations, better weather and changes in commuting habits. Then there is a decline in September-December 2012 which may be due to colder weather, public holidays or other external disruptions. The plot shows macro trends (growth, plateau, decline) but not micro patterns (weekly seasonality and effect of public holidays). Below, the effect of weather is incorporated into the modelling.

# Task Four: Decompose and assess the stationarity of time series data

The goal of this task is to break the series into trend, seasonality, and noise components, then assess whether the series is stationary. Stationarity means the mean, variance, and autocorrelation structure do not change over time — a key assumption for ARIMA modelling. Non-stationary data can lead to misleading correlations and poor forecasts.

**Step 1 - STL Decomposition**
We use seasonal-trend decomposition via Loess (STL) to identify the trend (long-term direction of data), seasonality (repeating patterns at fixed intervals e.g. weekly) and remainder (residual noise after removing trend and seasonality).

```{r}

p_stl <- plot_stl_diagnostics(
  .data      = data,
  .date_var  = dteday,
  .value     = cnt,
  .frequency = "7 days",
  .trend     = "3 months",
  .title = "STL Decomposition of Daily Bike Rentals",
  .y_lab = "Count of Bike Rentals"
)



decomp_tbl <- tk_stl_diagnostics(
  .data      = data,
  .date_var  = dteday,
  .value     = cnt,
  .frequency = "7 days",
  .trend     = "3 months"

)
```

**Step 2 - ACT/PACF of Remainder**


```{r}
p_acf_remainder <- plot_acf_diagnostics(
  .data     = decomp_tbl,
  .date_var = dteday,
  .value    = remainder,
  .lags     = 60,
  .title = "ACF & PACF of STL Remainder (Deseasonalised Residuals)"
)
p_acf_remainder

```

*Interpretation*
- ACF shows a large spike at lag 1 (~0.9) with slow exponential decay over lags 2–10, suggesting strong autocorrelation and non-stationarity.

- PACF shows a large spike at lag 1, with subsequent lags near zero — consistent with an AR(1) process.

- No strong weekly seasonal spike is visible.

**Step 3 - Stationarity Test (ADF) on Raw Series**

Using Augmented Dickey-Fuller (ADF) test to statistically confirm stationarity.

```{r}
# Test for stationarity on the dataset
adf.test(data$cnt)
## data:  data$cnt
##Dickey-Fuller = -1.6351, Lag order = 9, p-value = 0.7327
##alternative hypothesis: stationary --> p-value > 0.05 so fail to reject null hypothesis --> series is likely non-stationary
```

*Conclusion for Task 4*
- The series shows strong autocorrelation and fails ADF for stationarity.
- Differencing (first and seasonal) is needed before fitting ARIMA.

# Task Five: Fit and forecast time series data using ARIMA models

Given the series is non-stationary, we apply differencing to achieve stationarity before fitting an ARIMA model. ARIMA has both seasonal and non-seasonal components:

General form: ARIMA(p, d, q)(P, D, Q)[s]

## Component	Meaning
p	Non-seasonal autoregressive (AR) order. p = 1, uses 1 lag of pass values (AR(1)) "yesterday's value"
d	Non-seasonal differencing to remove trend. d = 1, first difference applied to make the series stationary.
q	Non-seasonal moving average (MA) order. q = 1, uses 1 lag of the error terms (MA(1))
These parameters capture the short-term autocorrelation and trend

P	Seasonal AR order. P = 1, 1 seasonal lag of past values i.e. value 7 days ago
D	Seasonal differencing order. D = 0, no seasonal differencing - data was already de-seasoned or did not require seasonal diff.
Q	Seasonal MA order. Q = 2, 2 seasonal lags of the error terms (i.e. errors from 7 and 14 days ago)
[s]	Season length (period of the seasonality, e.g., 7 for weekly seasonality). s = 7, weekly seasonality.
This captures the repeating weekly patterns in the data.

**Step 1 - Differencing and Stationarity Check**

```{r}
# run test again after differencing
cnt_diff1 <- diff(data$cnt, lag = 1)

adf.test(na.omit(cnt_diff1))
## data:  na.omit(cnt_diff1)
## Dickey-Fuller = -13.798, Lag order = 8, p-value = 0.01
## alternative hypothesis: stationary --> p-value < 0.05 --> reject null hypothesis --> series is stationary --> can use ARIMA

# run after seasonal and first differencing (weekly seasonality = 7 day lag)
cnt_diff1_7 <- diff(cnt_diff1, lag = 7) 

adf.test(na.omit(cnt_diff1_7))
## data:  na.omit(cnt_diff1_7)
##Dickey-Fuller = -16.339, Lag order = 8, p-value = 0.01
##alternative hypothesis: stationary --> p < 0.05 --> likely stationary


# plot raw and differenced
# Raw series
acf_raw <- plot_acf_diagnostics(
  .data     = data,
  .date_var = dteday,
  .value    = cnt,
  .lags     = 60,
  .title    = "Raw Series: ACF & PACF"
)

acf_raw

# First + seasonal differencing
data_diff <- data %>%
  mutate(
    cnt_diff1 = c(NA, diff(cnt, lag = 1)),
    cnt_diff1_7 = c(rep(NA, 7), diff(c(NA, diff(cnt, lag = 1)), lag = 7))
  ) %>%
  drop_na(cnt_diff1_7)
head(data_diff)


acf_diff <- plot_acf_diagnostics(
  .data     = data_diff,
  .date_var = dteday,
  .value    = cnt_diff1_7,
  .lags     = 60,
  .title    = "Differenced Series: ACF & PACF"
)

acf_diff




```
*Interpretation*
Before differencing :
ACF: large spike at lag 1 with slow decay --> strong autocorrelation
PACF: large spike at lag 1, others near 0 --> AR(1) behaviour
--> non-stationarity

After differencing:
ACF: immediate drop after lag 0, no prolonged decay --> reduced autocorrelation
PACF: no significant spikes after lag 0
--> stationarity confirmed --> ARIMA can be used


**Step 2 - Fit ARIMA model**
```{r}

# Modeltime-friendly version
model <- arima_reg() %>%
  set_engine("auto_arima") %>%
  fit(cnt ~ dteday, data = data)

model_tbl <- modeltime_table(model)

model_calibrated <- model_tbl %>%
  modeltime_calibrate(new_data = data)
```

**Step 3 - Forecast with Confidence Intervals**

```{r}

model_calibrated %>%
  modeltime_forecast(h = "30 days", actual_data = data, conf_interval_show = TRUE) %>%
  plot_modeltime_forecast(
    .conf_interval_alpha = 0.2,
    .title = "30-Day Forecast with 95% Confidence Intervals"
  )
```

*Interpretation:*

- The 95% confidence interval (CI) indicates the range within which the true mean number of bike rentals is expected to fall 95% of the time.

- CI is narrow in the short term (first week), moderately wide in weeks 2–3, and widens substantially after that — reflecting increasing uncertainty over time.

- Historical data shows large swings (e.g., April and November 2012), so some volatility in the forecast is expected.

- CI is symmetrical, suggesting no systematic bias.

**Step 4 - Comparison of ARIMA and ARIMAX Models**


```{r}

library(dplyr)
library(timetk)
library(modeltime)
library(parsnip)

# 0) Clean & features ----------------------------------------------------------
data <- data %>%
  mutate(
    dteday = as.Date(dteday),
    temp_c = temp * 41
  ) %>%
  arrange(dteday)

# Baseline ARIMA (NO xregs, requires cnt ~ 1)
arima_model <- arima_reg() %>%
  set_engine("auto_arima") %>%
  fit(cnt ~ dteday, data = data)


# ARIMAX with xregs
arimax_model <- arima_reg() %>%
  set_engine("auto_arima") %>%
  fit(cnt ~ dteday + temp_c + hum + windspeed, data = data)

model_tbl <- modeltime_table(arima_model, arimax_model)

refit_tbl <- model_tbl %>%
  modeltime_refit(data = data)

refit_tbl %>%
  modeltime_forecast(
    new_data = data,
    actual_data = data
  ) %>%
  plot_modeltime_forecast(
    .title = "ARIMA vs ARIMAX In-Sample Fit",
    .conf_interval_alpha = 0.2
  )
# 5) Accuracy on the calibration window ---------------------------------------
refit_tbl %>%
  modeltime_calibrate(new_data = data) %>%
  modeltime_accuracy()

# Inspect selected specs if curious
arima_model$fit
arimax_model$fit



``` 



# Step 5 — ARIMA vs ARIMAX (Out-of-sample holdout test)

```{r}
# ---- Train/Test split (time-based) --------------------------------------
split_date <- as.Date("2012-07-01")
splits <- timetk::time_series_split(
  data,
  assess     = nrow(dplyr::filter(data, dteday >= split_date)),
  cumulative = TRUE
)
training <- rsample::training(splits)
testing  <- rsample::testing(splits)

# ---- Fit on TRAINING only ------------------------------------------------
arima_model  <- arima_reg() %>% set_engine("auto_arima") %>% fit(cnt ~ dteday, data = training)
arimax_model <- arima_reg() %>% set_engine("auto_arima") %>% fit(cnt ~ dteday + temp_c + hum + windspeed, data = training)

models_tbl <- modeltime_table(arima_model, arimax_model)

# ---- Calibrate + accuracy on TESTING ------------------------------------
calibration_tbl <- models_tbl %>% modeltime_calibrate(new_data = testing)
accuracy_tbl    <- calibration_tbl %>% modeltime_accuracy()
accuracy_tbl

# ---- Forecast on TESTING (ensure xregs present) -------------------------
testing_xreg <- testing %>% dplyr::select(dteday, cnt, temp_c, hum, windspeed)
fc_holdout <- calibration_tbl %>%
  modeltime_forecast(new_data = testing_xreg, actual_data = data)

# ---- Plot with short legend labels --------------------------------------
plot_df <- fc_holdout %>%
  filter(.key %in% c("actual", "prediction")) %>%
  mutate(series = case_when(
    .key == "actual" ~ "Actual",
    .key == "prediction" & str_detect(.model_desc, "^ARIMA\\(") ~ "ARIMA",
    .key == "prediction" & str_detect(.model_desc, "^REGRESSION WITH ARIMA") ~ "ARIMAX",
    TRUE ~ NA_character_
  )) %>%
  filter(!is.na(series)) %>%
  mutate(series = factor(series, levels = c("Actual", "ARIMA", "ARIMAX")))

p_holdout <- ggplot(plot_df, aes(x = .index, y = .value, colour = series)) +
  geom_line(linewidth = 0.8) +
  scale_colour_manual(values = c("Actual" = "black",
                                 "ARIMA"  = "#e41a1c",
                                 "ARIMAX" = "#1b9e77")) +
  labs(title = "Out-of-Sample Forecast: ARIMA vs ARIMAX (2012 H2 Holdout)",
       x = NULL, y = "Daily Rentals", colour = NULL) +
  theme_minimal(base_size = 12) +
  theme(legend.position = "bottom")

p_holdout


print(p_holdout)
ggsave("holdout_arima_vs_arimax.png", p_holdout, width = 10, height = 6, dpi = 300)

# ===== 6) Future projection (ARIMA only, with 95% CIs) =======================
# Label series explicitly

# Refit ARIMA on full history (no xregs) and calibrate to enable CIs
refit_arima_only <- modeltime_table(
  arima_reg() %>% set_engine("auto_arima") %>% fit(cnt ~ dteday, data = data)
) %>% modeltime_refit(data = data)

cal_future <- refit_arima_only %>% modeltime_calibrate(new_data = data)

# 30-day forecast beyond the last date in `data`
fc_future <- cal_future %>%
  modeltime_forecast(h = "30 days", actual_data = data, conf_interval_show = TRUE)



# Build a simple, robust dataframe for plotting
future_df <- fc_future %>%
  filter(.key %in% c("actual", "prediction", "conf_lo", "conf_hi")) %>%
  mutate(series = case_when(
    .key == "actual"     ~ "Actual",
    .key == "prediction" ~ "ARIMA",   # <- unconditionally label predictions as ARIMA here
    TRUE                 ~ NA_character_
  ))

# Optional sanity checks:
# dplyr::count(future_df, .key)
# dplyr::count(future_df, series)

p_future <- ggplot() +
  # CI ribbon if available
  { if (all(c(".conf_lo", ".conf_hi") %in% names(future_df))) 
      geom_ribbon(
        data = filter(future_df, .key == "prediction"),
        aes(x = .index, ymin = .conf_lo, ymax = .conf_hi),
        alpha = 0.15
      )
    else NULL } +
  # Actuals
  geom_line(
    data = filter(future_df, series == "Actual"),
    aes(x = .index, y = .value, colour = "Actual"),
    linewidth = 0.8
  ) +
  # ARIMA forecast
  geom_line(
    data = filter(future_df, series == "ARIMA"),
    aes(x = .index, y = .value, colour = "ARIMA"),
    linewidth = 0.8
  ) +
  scale_colour_manual(values = c("Actual" = "black", "ARIMA" = "#e41a1c")) +
  labs(
    title = "30-Day Projection with 95% CIs (ARIMA, refit on full history)",
    x = NULL, y = "Daily Rentals", colour = NULL
  ) +
  theme_minimal(base_size = 12) +
  theme(legend.position = "bottom")

p_future
ggsave("future_30d_projection.png", p_future, width = 10, height = 6, dpi = 300)


```

*Interpretation*

ARIMA and ARIMAX models are compared in the figure. ARIMAX - the green line - tracks the shape of the actual time series (black). That means that the weather variables (temperature, humidity and wind speed) explain some of the variance. ARIMA is underperforming because - as a univariate model with strong seasonal influence - it is just modelling a long term trend. 

The residuals on ARIMAX are lower than ARIMA, as is the AIC. It is the better model. The ARIMAX coefficients show that warmer weather means more rentals but higher humidity or higher wind speed mean fewer rentals.  The absolute values  of the coefficients are large and have relatively small standard errors, suggesting that the coefficients are statistically significant. The magnitudes are large, suggesting a strong effect. It may also suggest multicollinearity.


To evaluate real predictive skill, models were trained on data up to June 30, 2012 and tested on the remaining six months. This prevents overfitting to the full dataset and shows how well each model generalises.

- ARIMAX predictions in the holdout window track the actual values much more closely than ARIMA, capturing both seasonal patterns and large fluctuations in late 2012.

- ARIMA underestimates variability, producing smoother forecasts that miss short-term peaks and drops.

- Test set error metrics confirm ARIMAX’s superiority, with lower RMSE and MAPE than ARIMA.

- This demonstrates that weather variables significantly improve the model’s ability to forecast daily demand in unseen periods.

- A separate ARIMA model was refitted on the full history to generate a 30-day projection beyond Dec 31, 2012. Extending ARIMAX into the future would require assumptions for future temperature, humidity, and windspeed.



# Task Six: Findings and Conclusions

## 1. Data Characteristics

- The dataset contains 731 daily observations from the Capital Bikeshare system covering January 2011 to December 2012.

- Features include date, weather, seasonal factors, and total bike rental counts (cnt), with casual and registered user breakdowns.

## 2. Trend and Seasonality

- The smoothed time series plot of daily rentals (cnt) shows a clear upward trend over time.

- STL decomposition revealed a weekly seasonal pattern, with higher rentals on specific days of the week.

- However, the seasonal component is less dominant than the trend and random fluctuation components, especially in the first year.

## 3. Stationarity and Autocorrelation

- ACF of the original series showed a strong lag-1 autocorrelation (~0.9) and a slow, exponential decay across further lags, indicating non-stationarity.

- PACF showed a significant spike at lag 1 with all other lags close to zero — typical for an AR(1) process.

- After differencing (first and seasonal), ACF/PACF diagnostics confirmed the series became more stationary and suitable for ARIMA modeling.

## 4. Model Fit Comparison: ARIMA and ARIMAX

**ARIMA(1,1,1)(1,0,2)[7]:**

- This model captures trend and weekly cycles.

- AIC = 12,041.75; residual variance (σ²) = 844,004

- In-sample fit shows reasonable tracking but fails to adapt to late-2012 rental drops.

**ARIMAX (with temperature, humidity, windspeed):**

- Regression with ARIMA(2,1,1) errors and weather covariates.

- AIC = 11,791.54; residual variance = 598,871

- Weather variables significantly improve explanatory power:

  - temp_c: positive influence

  - humidity and wind speed: strong negative effects

ARIMAX substantially outperforms ARIMA, indicating that weather is a critical driver of daily bike rental counts.



## 5. Forecasting

- A 30-day forecast was generated using the ARIMA model.

- The forecast captured the ongoing upward trend and preserved weekly seasonality in projected values.

- The forecast interval provides useful insights into expected rental demand and uncertainty bounds.

## 6. Conclusion

- The time series of daily bike rentals is non-stationary and shows both trend and weekly seasonality.

- ARIMAX clearly outperforms ARIMA for short-term forecasting due to the inclusion of weather effects.

- This model could be used to support short-term operational planning (e.g. staffing, bike redistribution) within the bikeshare system.

## 7. Recommendations for Future Work

- Extend ARIMAX with lagged and interaction terms
- Compare more models e.g. Prophet and XGBoost
- Segment by user type (casual vs registered)
- Longer term seasonality: consider monthly/yearly cycles with weekly aggregation.



